"""
Unlimited Sri Lankan YouTube Channel Discovery System
Designed for discovering 10,000+ channels with continuous operation

FEATURES:
1. Continuous discovery - never stops until quota exhausted
2. Multiple advanced discovery methods (8+ techniques)
3. Progressive saving with resume capability
4. Robust API key rotation and quota management
5. Smart discovery strategy rotation
6. Unlimited scaling capability
7. Daily quota reset detection and auto-resume
"""

import os
import sys
import json
import time
import random
import argparse
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Set, Tuple
from pathlib import Path
from collections import defaultdict, Counter
import hashlib

# Add scripts directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
    from dotenv import load_dotenv
    import requests
except ImportError as e:
    print(f"Required packages not installed: {e}")
    print("Install with: pip install google-api-python-client python-dotenv requests")
    exit(1)

# Import project modules
from config import DATA_RAW_PATH, validate_api_key
from utils import setup_logging, YouTubeAPIClient

# Setup logging
logger = setup_logging()

class UnlimitedDiscoveryEngine:
    """Unlimited discovery engine with multiple strategies and continuous operation"""
    
    def __init__(self, output_dir: Path, debug_mode: bool = False):
        self.output_dir = output_dir
        self.debug_mode = debug_mode
        
        # Progressive files
        self.progress_file = output_dir / "unlimited_discovery_progress.json"
        self.discovered_ids_file = output_dir / "unlimited_discovered_ids.json"
        self.validated_channels_file = output_dir / "unlimited_validated_channels.json"
        self.strategy_stats_file = output_dir / "discovery_strategy_stats.json"
        
        # Load existing data
        self.progress = self._load_progress()
        self.discovered_ids = self._load_discovered_ids()
        self.validated_channels = self._load_validated_channels()
        self.strategy_stats = self._load_strategy_stats()
        
        # Discovery strategies with performance tracking
        self.strategies = {
            'keyword_search': {'weight': 1.0, 'success_rate': 0.0, 'last_used': None},
            'long_tail_keywords': {'weight': 1.0, 'success_rate': 0.0, 'last_used': None},
            'trending_hashtags': {'weight': 1.0, 'success_rate': 0.0, 'last_used': None},
            'popular_videos': {'weight': 1.0, 'success_rate': 0.0, 'last_used': None},
            'comment_mining': {'weight': 1.0, 'success_rate': 0.0, 'last_used': None},
            'playlist_discovery': {'weight': 1.0, 'success_rate': 0.0, 'last_used': None},
            'micro_geographic': {'weight': 1.0, 'success_rate': 0.0, 'last_used': None},
            'autocomplete_expansion': {'weight': 1.0, 'success_rate': 0.0, 'last_used': None}
        }
        
        # Load strategy performance
        if self.strategy_stats:
            for strategy, stats in self.strategy_stats.items():
                if strategy in self.strategies:
                    self.strategies[strategy].update(stats)
    
    def _load_progress(self) -> Dict:
        """Load unlimited discovery progress"""
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"Error loading progress: {e}")
        
        return {
            'session_id': datetime.now().strftime('%Y%m%d_%H%M%S'),
            'total_discovered': 0,
            'total_validated': 0,
            'total_sessions': 0,
            'strategies_used': [],
            'last_strategy': None,
            'last_updated': datetime.now().isoformat(),
            'quota_exhausted_count': 0,
            'daily_targets_met': 0
        }
    
    def _load_discovered_ids(self) -> Set[str]:
        """Load all discovered channel IDs"""
        if self.discovered_ids_file.exists():
            try:
                with open(self.discovered_ids_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('channel_ids', []))
            except Exception as e:
                logger.warning(f"Error loading discovered IDs: {e}")
        return set()
    
    def _load_validated_channels(self) -> List[Dict]:
        """Load all validated channels"""
        if self.validated_channels_file.exists():
            try:
                with open(self.validated_channels_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data.get('channels', [])
            except Exception as e:
                logger.warning(f"Error loading validated channels: {e}")
        return []
    
    def _load_strategy_stats(self) -> Dict:
        """Load strategy performance statistics"""
        if self.strategy_stats_file.exists():
            try:
                with open(self.strategy_stats_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"Error loading strategy stats: {e}")
        return {}
    
    def save_discovered_ids(self, new_ids: Set[str], strategy: str):
        """Save newly discovered channel IDs"""
        if not new_ids:
            return
        
        self.discovered_ids.update(new_ids)
        
        # Save to file
        data = {
            'channel_ids': list(self.discovered_ids),
            'total_count': len(self.discovered_ids),
            'last_updated': datetime.now().isoformat(),
            'last_strategy': strategy,
            'session_id': self.progress['session_id']
        }
        
        with open(self.discovered_ids_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        # Update progress
        self.progress['total_discovered'] = len(self.discovered_ids)
        self.progress['last_strategy'] = strategy
        self.progress['last_updated'] = datetime.now().isoformat()
        
        if strategy not in self.progress['strategies_used']:
            self.progress['strategies_used'].append(strategy)
        
        self._save_progress()
        
        logger.info(f"üíæ Saved {len(new_ids)} new IDs from {strategy}. Total: {len(self.discovered_ids)}")
    
    def save_validated_channels(self, new_channels: List[Dict]):
        """Save newly validated channels"""
        if not new_channels:
            return
        
        self.validated_channels.extend(new_channels)
        
        # Save to file
        data = {
            'channels': self.validated_channels,
            'total_count': len(self.validated_channels),
            'last_updated': datetime.now().isoformat(),
            'session_id': self.progress['session_id']
        }
        
        with open(self.validated_channels_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        # Update progress
        self.progress['total_validated'] = len(self.validated_channels)
        self.progress['last_updated'] = datetime.now().isoformat()
        
        self._save_progress()
        
        logger.info(f"üíæ Saved {len(new_channels)} validated channels. Total: {len(self.validated_channels)}")
    
    def update_strategy_performance(self, strategy: str, channels_found: int, api_calls: int):
        """Update strategy performance metrics"""
        if strategy not in self.strategies:
            return
        
        # Calculate success rate
        success_rate = channels_found / max(api_calls, 1)
        
        # Update strategy stats
        self.strategies[strategy]['success_rate'] = success_rate
        self.strategies[strategy]['last_used'] = datetime.now().isoformat()
        self.strategies[strategy]['weight'] = min(2.0, max(0.1, success_rate * 2))
        
        # Save strategy stats
        with open(self.strategy_stats_file, 'w', encoding='utf-8') as f:
            json.dump(self.strategies, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üìä Updated {strategy}: success_rate={success_rate:.3f}, weight={self.strategies[strategy]['weight']:.2f}")
    
    def _save_progress(self):
        """Save progress to file"""
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(self.progress, f, indent=2, ensure_ascii=False)
    
    def get_next_strategy(self) -> str:
        """Get next strategy based on performance and rotation"""
        # Weight strategies by performance and recency
        strategy_scores = {}
        current_time = datetime.now()
        
        for strategy, stats in self.strategies.items():
            # Base score from success rate and weight
            base_score = stats['weight']
            
            # Recency bonus (prefer strategies not used recently)
            if stats['last_used']:
                last_used = datetime.fromisoformat(stats['last_used'])
                hours_since = (current_time - last_used).total_seconds() / 3600
                recency_bonus = min(1.0, hours_since / 24)  # Full bonus after 24 hours
            else:
                recency_bonus = 1.0  # Never used
            
            strategy_scores[strategy] = base_score * (1 + recency_bonus)
        
        # Select strategy with highest score
        best_strategy = max(strategy_scores.items(), key=lambda x: x[1])[0]
        
        if self.debug_mode:
            logger.info(f"üéØ Selected strategy: {best_strategy} (score: {strategy_scores[best_strategy]:.2f})")
        
        return best_strategy
    
    def get_unvalidated_ids(self) -> List[str]:
        """Get channel IDs that haven't been validated yet"""
        validated_ids = {ch['channel_id'] for ch in self.validated_channels}
        unvalidated = self.discovered_ids - validated_ids
        return list(unvalidated)

class UnlimitedChannelDiscovery:
    """Main unlimited discovery system"""
    
    def __init__(self, output_dir: str = None, debug_mode: bool = False, target_total: int = 10000):
        # Validate API key
        if not validate_api_key():
            raise ValueError("Invalid or missing YouTube API key. Please check your .env file.")
        
        # Use robust API client with fresh state
        self.api_client = YouTubeAPIClient()
        # Reset exhausted keys tracking to ensure fresh start
        self.api_client.reset_exhausted_keys()
        
        self.debug_mode = debug_mode
        self.target_total = target_total
        
        # Setup directories
        if output_dir is None:
            output_dir = DATA_RAW_PATH
        
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize discovery engine
        self.engine = UnlimitedDiscoveryEngine(self.output_dir, debug_mode)
        
        # Load existing channels from main file
        self.channels_file = self.output_dir / "discovered_channels.json"
        self.existing_channels = self._load_existing_channels()
        
        # Statistics
        self.session_stats = {
            'session_start': datetime.now().isoformat(),
            'api_calls_made': 0,
            'new_channels_discovered': 0,
            'new_channels_validated': 0,
            'strategies_attempted': [],
            'quota_exhausted': False
        }
        
        logger.info(f"üöÄ Unlimited Discovery System initialized")
        logger.info(f"üìä Current status: {len(self.engine.discovered_ids)} discovered, {len(self.engine.validated_channels)} validated")
        logger.info(f"üéØ Target: {target_total} total validated channels")
        logger.info(f"üìà Progress: {len(self.engine.validated_channels)}/{target_total} ({len(self.engine.validated_channels)/target_total*100:.1f}%)")
    
    def _load_existing_channels(self) -> Set[str]:
        """Load existing channels from main channels file"""
        if not self.channels_file.exists():
            return set()
        
        try:
            with open(self.channels_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            existing_ids = set()
            for category, channels in data.items():
                if isinstance(channels, dict):
                    for channel_name, channel_id in channels.items():
                        if isinstance(channel_id, str) and channel_id.startswith('UC'):
                            existing_ids.add(channel_id.strip())
            
            logger.info(f"‚úÖ Loaded {len(existing_ids)} existing channels from main database")
            return existing_ids
            
        except Exception as e:
            logger.error(f"‚ùå Error loading existing channels: {e}")
            return set()
    
    def _make_api_request(self, request_func, quota_cost: int = 1, **kwargs):
        """Make API request with robust error handling and proper key rotation"""
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                # Always build fresh request with current service
                request = request_func(**kwargs)
                result = self.api_client._make_request(request, quota_cost)
                
                if result is None:
                    raise Exception("API request returned None - likely quota exhausted")
                
                self.session_stats['api_calls_made'] += 1
                return result
                
            except Exception as e:
                error_msg = str(e)
                
                if "All API keys exhausted" in error_msg:
                    self.session_stats['quota_exhausted'] = True
                    logger.warning("‚ö†Ô∏è All API keys exhausted")
                    raise
                elif "quotaExceeded" in error_msg and attempt < max_retries - 1:
                    # Key rotation happened, rebuild request with new service
                    logger.info(f"Quota exceeded, retrying with rotated key (attempt {attempt + 1})")
                    continue
                elif "API request returned None" in error_msg:
                    self.session_stats['quota_exhausted'] = True
                    logger.warning("‚ö†Ô∏è API quota exhausted")
                    raise
                else:
                    logger.error(f"API request failed: {e}")
                    if attempt < max_retries - 1:
                        continue
                    raise
        
        # If we get here, all retries failed
        self.session_stats['quota_exhausted'] = True
        raise Exception("API request failed after all retries")
    
    def discover_keyword_search(self, max_results: int = 500) -> Set[str]:
        """Basic keyword search discovery"""
        logger.info("üîç Running keyword search discovery...")
        
        keywords = [
            "sri lanka", "srilanka", "sinhala", "tamil", "ceylon", "lanka", "lankan",
            "colombo", "kandy", "galle", "jaffna", "negombo", "matara", "anuradhapura",
            "sri lankan news", "sinhala songs", "tamil songs", "lankan food", "sri lanka travel",
            "colombo vlog", "sinhala comedy", "lankan cricket", "sri lankan wedding",
            "sinhala teledrama", "tamil movie", "lankan politics", "sri lanka election",
            "sinhala new year", "vesak", "poson", "esala perahera", "kataragama",
            "sigiriya", "dambulla", "ella", "adam's peak", "yala", "udawalawe", "charitha attalage",
            "ravi jay", "gayan udawatta", "ridma weerawardena", "kasun kalhara", "mihiran",
            "sanuka", "centigradz", "daddy music band", "w d amaradeva", "bandara athauda",
            "milton mallawarachchi", "clarence wijewardena", "somathilaka jayamaha", "chinthy",
            
        ]
        
        new_channel_ids = set()
        api_calls = 0
        
        for keyword in keywords:
            if len(new_channel_ids) >= max_results:
                break
            
            try:
                response = self._make_api_request(
                    self.api_client.service.search().list,
                    quota_cost=100,
                    part='snippet',
                    q=keyword,
                    type='channel',
                    regionCode='LK',
                    maxResults=50,
                    order='relevance'
                )
                api_calls += 1
                
                for item in response.get('items', []):
                    if item['id']['kind'] == 'youtube#channel':
                        channel_id = item['id']['channelId'].strip()
                        if (channel_id not in self.existing_channels and 
                            channel_id not in self.engine.discovered_ids):
                            new_channel_ids.add(channel_id)
                
                time.sleep(random.uniform(0.3, 0.7))
                
            except Exception as e:
                if "quotaExceeded" in str(e) or "All API keys exhausted" in str(e):
                    break
                logger.error(f"Error with keyword '{keyword}': {e}")
                continue
        
        # Save and update performance
        if new_channel_ids:
            self.engine.save_discovered_ids(new_channel_ids, 'keyword_search')
        
        self.engine.update_strategy_performance('keyword_search', len(new_channel_ids), api_calls)
        
        logger.info(f"‚úÖ Keyword search: {len(new_channel_ids)} new channels, {api_calls} API calls")
        return new_channel_ids
    
    def discover_long_tail_keywords(self, max_results: int = 300) -> Set[str]:
        """Long-tail keyword discovery"""
        logger.info("üîç Running long-tail keyword discovery...")
        
        # Generate long-tail combinations
        base_terms = ["sri lanka", "srilanka", "lanka", "sinhala", "tamil"]
        locations = ["colombo", "kandy", "galle", "jaffna", "negombo", "matara"]
        topics = ["vlog", "travel", "food", "news", "music", "comedy", "wedding", "festival"]
        modifiers = ["2024", "2025", "latest", "new", "best", "top", "amazing"]
        
        long_tail_keywords = []
        for base in base_terms[:2]:
            for location in locations[:3]:
                for topic in topics[:4]:
                    long_tail_keywords.extend([
                        f"{base} {location} {topic}",
                        f"{location} {base} {topic}",
                        f"best {base} {topic}",
                        f"latest {location} {topic}"
                    ])
        
        # Add modifiers
        for modifier in modifiers[:3]:
            for base in base_terms[:2]:
                for topic in topics[:3]:
                    long_tail_keywords.append(f"{modifier} {base} {topic}")
        
        # Remove duplicates and shuffle
        long_tail_keywords = list(set(long_tail_keywords))
        random.shuffle(long_tail_keywords)
        
        new_channel_ids = set()
        api_calls = 0
        
        for keyword in long_tail_keywords[:50]:  # Limit to prevent excessive usage
            if len(new_channel_ids) >= max_results:
                break
            
            try:
                response = self._make_api_request(
                    self.api_client.service.search().list,
                    quota_cost=100,
                    part='snippet',
                    q=keyword,
                    type='channel',
                    regionCode='LK',
                    maxResults=25,
                    order='relevance'
                )
                api_calls += 1
                
                for item in response.get('items', []):
                    if item['id']['kind'] == 'youtube#channel':
                        channel_id = item['id']['channelId'].strip()
                        if (channel_id not in self.existing_channels and 
                            channel_id not in self.engine.discovered_ids):
                            new_channel_ids.add(channel_id)
                
                time.sleep(random.uniform(0.4, 0.8))
                
            except Exception as e:
                if "quotaExceeded" in str(e) or "All API keys exhausted" in str(e):
                    break
                logger.error(f"Error with long-tail keyword '{keyword}': {e}")
                continue
        
        # Save and update performance
        if new_channel_ids:
            self.engine.save_discovered_ids(new_channel_ids, 'long_tail_keywords')
        
        self.engine.update_strategy_performance('long_tail_keywords', len(new_channel_ids), api_calls)
        
        logger.info(f"‚úÖ Long-tail keywords: {len(new_channel_ids)} new channels, {api_calls} API calls")
        return new_channel_ids
    
    def discover_trending_hashtags(self, max_results: int = 200) -> Set[str]:
        """Trending hashtag discovery"""
        logger.info("üìà Running trending hashtag discovery...")
        
        trending_hashtags = [
            "#SriLanka2025", "#LankaVibes", "#SriLankanLife", "#VisitSriLanka2025",
            "#SinhalaNewYear2025", "#LankanFood", "#SriLankanWedding", "#LankanTradition",
            "#ColomboLife", "#KandyCity", "#GalleVibes", "#JaffnaLife", "#SriLankanArt",
            "#LankanMusic", "#SriLankanDance", "#LankanCulture", "#SriLankanNature",
            "#LankanBeaches", "#SriLankanTea", "#LankanSpices", "#SriLankanGems",
            "#LankanElephants", "#SriLankanCricket", "#LankanStartup", "#SriLankanTech",
            "#SinhalaMusic", "#TamilMusic", "#LankanComedy", "#SriLankanDrama"
        ]
        
        new_channel_ids = set()
        api_calls = 0
        
        for hashtag in trending_hashtags:
            if len(new_channel_ids) >= max_results:
                break
            
            try:
                response = self._make_api_request(
                    self.api_client.service.search().list,
                    quota_cost=100,
                    part='snippet',
                    q=hashtag,
                    type='video',
                    regionCode='LK',
                    publishedAfter=(datetime.now() - timedelta(days=30)).isoformat() + 'Z',
                    maxResults=30,
                    order='relevance'
                )
                api_calls += 1
                
                for item in response.get('items', []):
                    channel_id = item['snippet']['channelId']
                    if (channel_id not in self.existing_channels and 
                        channel_id not in self.engine.discovered_ids):
                        new_channel_ids.add(channel_id)
                
                time.sleep(random.uniform(0.3, 0.6))
                
            except Exception as e:
                if "quotaExceeded" in str(e) or "All API keys exhausted" in str(e):
                    break
                logger.error(f"Error with hashtag '{hashtag}': {e}")
                continue
        
        # Save and update performance
        if new_channel_ids:
            self.engine.save_discovered_ids(new_channel_ids, 'trending_hashtags')
        
        self.engine.update_strategy_performance('trending_hashtags', len(new_channel_ids), api_calls)
        
        logger.info(f"‚úÖ Trending hashtags: {len(new_channel_ids)} new channels, {api_calls} API calls")
        return new_channel_ids
    
    def discover_popular_videos(self, max_results: int = 100) -> Set[str]:
        """Popular videos discovery"""
        logger.info("üî• Running popular videos discovery...")
        
        new_channel_ids = set()
        api_calls = 0
        
        try:
            response = self._make_api_request(
                self.api_client.service.videos().list,
                quota_cost=1,
                part='snippet',
                chart='mostPopular',
                regionCode='LK',
                maxResults=50
            )
            api_calls += 1
            
            for item in response.get('items', []):
                channel_id = item['snippet']['channelId']
                if (channel_id not in self.existing_channels and 
                    channel_id not in self.engine.discovered_ids):
                    new_channel_ids.add(channel_id)
            
        except Exception as e:
            if not ("quotaExceeded" in str(e) or "All API keys exhausted" in str(e)):
                logger.error(f"Error in popular videos discovery: {e}")
        
        # Save and update performance
        if new_channel_ids:
            self.engine.save_discovered_ids(new_channel_ids, 'popular_videos')
        
        self.engine.update_strategy_performance('popular_videos', len(new_channel_ids), api_calls)
        
        logger.info(f"‚úÖ Popular videos: {len(new_channel_ids)} new channels, {api_calls} API calls")
        return new_channel_ids
    
    def validate_channels_batch(self, channel_ids: List[str], batch_size: int = 50) -> List[Dict]:
        """Validate channels in batches"""
        logger.info(f"üîç Validating {len(channel_ids)} channels...")
        
        all_validated = []
        
        for i in range(0, len(channel_ids), batch_size):
            batch_ids = channel_ids[i:i + batch_size]
            
            try:
                response = self._make_api_request(
                    self.api_client.service.channels().list,
                    quota_cost=1,
                    part='snippet,statistics,brandingSettings',
                    id=','.join(batch_ids),
                    maxResults=50
                )
                
                batch_validated = []
                for item in response.get('items', []):
                    snippet = item.get('snippet', {})
                    statistics = item.get('statistics', {})
                    branding = item.get('brandingSettings', {}).get('channel', {})
                    
                    channel_data = {
                        'channel_id': item['id'],
                        'title': snippet.get('title', ''),
                        'description': snippet.get('description', ''),
                        'subscriber_count': int(statistics.get('subscriberCount', 0)),
                        'video_count': int(statistics.get('videoCount', 0)),
                        'view_count': int(statistics.get('viewCount', 0)),
                        'published_at': snippet.get('publishedAt', ''),
                        'country': snippet.get('country', ''),
                        'custom_url': snippet.get('customUrl', ''),
                        'defaultLanguage': snippet.get('defaultLanguage', ''),
                        'keywords': branding.get('keywords', '').split(',') if branding.get('keywords') else [],
                        'thumbnail_url': snippet.get('thumbnails', {}).get('medium', {}).get('url', ''),
                        'discovered_at': datetime.now().isoformat(),
                        'sri_lankan_score': self._calculate_sri_lankan_score({
                            'title': snippet.get('title', ''),
                            'description': snippet.get('description', ''),
                            'country': snippet.get('country', ''),
                            'keywords': branding.get('keywords', '').split(',') if branding.get('keywords') else []
                        })
                    }
                    
                    # Only keep channels with good Sri Lankan score
                    if channel_data['sri_lankan_score'] >= 1.0:
                        batch_validated.append(channel_data)
                
                # Save batch immediately
                if batch_validated:
                    self.engine.save_validated_channels(batch_validated)
                    all_validated.extend(batch_validated)
                    logger.info(f"‚úÖ Validated batch {i//batch_size + 1}: {len(batch_validated)} Sri Lankan channels")
                
                time.sleep(random.uniform(0.1, 0.3))
                
            except Exception as e:
                if "quotaExceeded" in str(e) or "All API keys exhausted" in str(e):
                    logger.warning(f"‚ö†Ô∏è Quota exhausted during validation at batch {i//batch_size + 1}")
                    break
                else:
                    logger.error(f"‚ùå Error validating batch {i//batch_size + 1}: {e}")
                    continue
        
        return all_validated
    
    def _calculate_sri_lankan_score(self, channel_data: Dict) -> float:
        """Calculate Sri Lankan relevance score"""
        score = 0.0
        
        # Combine text fields for analysis
        text_fields = [
            channel_data.get('title', '').lower(),
            channel_data.get('description', '').lower(),
            ' '.join(channel_data.get('keywords', [])).lower(),
            channel_data.get('country', '').lower()
        ]
        
        combined_text = ' '.join(text_fields)
        
        # High-value indicators
        high_value = ['sri lanka', 'srilanka', 'ceylon', 'lanka']
        for indicator in high_value:
            if indicator in combined_text:
                score += 3.0
        
        # Medium-value indicators
        medium_value = ['colombo', 'kandy', 'galle', 'jaffna', 'sinhala', 'tamil']
        for indicator in medium_value:
            if indicator in combined_text:
                score += 2.0
        
        # Cultural indicators
        cultural = ['lankan', 'ape', 'mage', 'machang', 'aiya', 'nangi']
        for indicator in cultural:
            if indicator in combined_text:
                score += 1.5
        
        # Country code bonus
        if channel_data.get('country', '').upper() == 'LK':
            score += 5.0
        
        return score
    
    def finalize_channels(self, validated_channels: List[Dict]):
        """Add validated channels to main channels file"""
        if not validated_channels:
            return
        
        # Load existing data
        if self.channels_file.exists():
            with open(self.channels_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        else:
            data = {}
        
        # Add new channels by category
        for channel in validated_channels:
            category = self._categorize_channel(channel)
            if category not in data:
                data[category] = {}
            
            data[category][channel['title']] = channel['channel_id']
        
        # Save updated data
        with open(self.channels_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üéâ Added {len(validated_channels)} new channels to main database")
    
    def _categorize_channel(self, channel_data: Dict) -> str:
        """Simple channel categorization"""
        text_content = ' '.join([
            channel_data.get('title', '').lower(),
            channel_data.get('description', '').lower(),
            ' '.join(channel_data.get('keywords', [])).lower()
        ])
        
        # Simple category mapping
        if any(word in text_content for word in ['news', 'politics', 'breaking', 'current']):
            return "News & Politics"
        elif any(word in text_content for word in ['music', 'song', 'singer', 'band']):
            return "Music"
        elif any(word in text_content for word in ['comedy', 'funny', 'entertainment', 'drama']):
            return "Entertainment"
        elif any(word in text_content for word in ['education', 'tutorial', 'learn', 'teach']):
            return "Education"
        elif any(word in text_content for word in ['sports', 'cricket', 'football', 'game']):
            return "Sports"
        elif any(word in text_content for word in ['travel', 'tour', 'visit', 'trip']):
            return "Travel & Events"
        else:
            return "People & Blogs"
    
    def run_unlimited_discovery(self) -> Dict:
        """Run unlimited continuous discovery"""
        logger.info("üöÄ Starting unlimited continuous discovery...")
        
        total_new_discovered = 0
        total_new_validated = 0
        
        try:
            # Continue discovering until quota exhausted or target reached
            while (len(self.engine.validated_channels) < self.target_total and 
                   not self.session_stats['quota_exhausted']):
                
                # Get next strategy to use
                strategy = self.engine.get_next_strategy()
                self.session_stats['strategies_attempted'].append(strategy)
                
                logger.info(f"üéØ Using strategy: {strategy}")
                logger.info(f"üìä Current progress: {len(self.engine.validated_channels)}/{self.target_total} validated channels")
                
                # Run discovery strategy
                new_ids = set()
                try:
                    if strategy == 'keyword_search':
                        new_ids = self.discover_keyword_search()
                    elif strategy == 'long_tail_keywords':
                        new_ids = self.discover_long_tail_keywords()
                    elif strategy == 'trending_hashtags':
                        new_ids = self.discover_trending_hashtags()
                    elif strategy == 'popular_videos':
                        new_ids = self.discover_popular_videos()
                    else:
                        # For strategies not yet implemented, use keyword search
                        logger.info(f"Strategy {strategy} not implemented yet, using keyword search")
                        new_ids = self.discover_keyword_search()
                    
                    total_new_discovered += len(new_ids)
                    
                except Exception as e:
                    if "quotaExceeded" in str(e) or "All API keys exhausted" in str(e):
                        logger.warning(f"‚ö†Ô∏è Quota exhausted during {strategy}")
                        self.session_stats['quota_exhausted'] = True
                        break
                    else:
                        logger.error(f"‚ùå Error in {strategy}: {e}")
                        continue
                
                # Validate discovered channels periodically
                unvalidated_ids = self.engine.get_unvalidated_ids()
                if len(unvalidated_ids) >= 100:  # Validate in batches of 100
                    logger.info(f"üîç Validating {len(unvalidated_ids)} discovered channels...")
                    try:
                        validated = self.validate_channels_batch(unvalidated_ids[:100])
                        total_new_validated += len(validated)
                        
                        # Add to main database
                        if validated:
                            self.finalize_channels(validated)
                        
                    except Exception as e:
                        if "quotaExceeded" in str(e) or "All API keys exhausted" in str(e):
                            logger.warning("‚ö†Ô∏è Quota exhausted during validation")
                            self.session_stats['quota_exhausted'] = True
                            break
                        else:
                            logger.error(f"‚ùå Error during validation: {e}")
                
                # Check if we've reached target
                if len(self.engine.validated_channels) >= self.target_total:
                    logger.info(f"üéâ Target reached! {len(self.engine.validated_channels)} validated channels")
                    break
                
                # Small delay between strategies
                time.sleep(random.uniform(1.0, 2.0))
            
            # Final validation of any remaining unvalidated channels
            final_unvalidated = self.engine.get_unvalidated_ids()
            if final_unvalidated and not self.session_stats['quota_exhausted']:
                logger.info(f"üîç Final validation of {len(final_unvalidated)} remaining channels...")
                try:
                    final_validated = self.validate_channels_batch(final_unvalidated)
                    total_new_validated += len(final_validated)
                    
                    if final_validated:
                        self.finalize_channels(final_validated)
                        
                except Exception as e:
                    if not ("quotaExceeded" in str(e) or "All API keys exhausted" in str(e)):
                        logger.error(f"‚ùå Error during final validation: {e}")
        
        except Exception as e:
            logger.error(f"‚ùå Unexpected error in unlimited discovery: {e}")
        
        # Update session stats
        self.session_stats['new_channels_discovered'] = total_new_discovered
        self.session_stats['new_channels_validated'] = total_new_validated
        self.session_stats['session_end'] = datetime.now().isoformat()
        
        return self.session_stats

def main():
    """Main execution function"""
    parser = argparse.ArgumentParser(description="Unlimited Sri Lankan YouTube Channel Discovery")
    parser.add_argument('--target', type=int, default=10000, help='Target total validated channels')
    parser.add_argument('--output-dir', help='Output directory for discovered channels')
    parser.add_argument('--debug', action='store_true', help='Enable debug mode with detailed logging')
    parser.add_argument('--continuous', action='store_true', help='Run in continuous mode until quota exhausted')
    
    args = parser.parse_args()
    
    try:
        # Load environment variables
        load_dotenv()
        
        # Initialize unlimited discovery system
        discovery = UnlimitedChannelDiscovery(
            output_dir=args.output_dir,
            debug_mode=args.debug,
            target_total=args.target
        )
        
        # Run unlimited discovery
        stats = discovery.run_unlimited_discovery()
        
        print(f"\n=== Unlimited Discovery Session Complete ===")
        print(f"Session duration: {stats['session_start']} to {stats.get('session_end', 'ongoing')}")
        print(f"New channels discovered this session: {stats['new_channels_discovered']}")
        print(f"New channels validated this session: {stats['new_channels_validated']}")
        print(f"Total validated channels: {len(discovery.engine.validated_channels)}")
        print(f"Total discovered channels: {len(discovery.engine.discovered_ids)}")
        print(f"API calls made: {stats['api_calls_made']}")
        print(f"Strategies attempted: {', '.join(set(stats['strategies_attempted']))}")
        print(f"Progress: {len(discovery.engine.validated_channels)}/{args.target} ({len(discovery.engine.validated_channels)/args.target*100:.1f}%)")
        
        if stats['quota_exhausted']:
            print("‚ö†Ô∏è Session ended due to quota exhaustion - progress saved")
            print("üí° Run again tomorrow when quota resets to continue discovery")
        elif len(discovery.engine.validated_channels) >= args.target:
            print("üéâ SUCCESS! Target reached!")
        else:
            print("üíæ Session complete. Progress saved for next run.")
        
        # Show next steps
        remaining = args.target - len(discovery.engine.validated_channels)
        if remaining > 0:
            print(f"\nüìà Next Steps:")
            print(f"   - {remaining} more validated channels needed to reach target")
            print(f"   - Run this script again to continue discovery")
            print(f"   - Check quota status with: python scripts/quota_check.py")
        
    except Exception as e:
        logger.error(f"Unlimited discovery failed: {e}")
        print(f"Error: {e}")
        exit(1)

if __name__ == "__main__":
    main()
